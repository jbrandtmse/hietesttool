# Story 1.1: SOAP/MTOM Integration Spike

## Status
Approved

## Story

**As a** technical lead,
**I want** to validate that zeep library can handle MTOM attachments for ITI-41,
**so that** I can confirm our SOAP library choice before committing to full implementation.

## Acceptance Criteria

1. Create minimal PIX Add SOAP message using zeep library
2. Construct basic ITI-41 SOAP envelope with MTOM attachment using zeep
3. Test MTOM attachment with sample CCD document (>10KB)
4. Verify SOAP envelope structure matches IHE ITI-41 specification requirements
5. Confirm Content-ID references work correctly between metadata and attachment
6. Test against mock ITI-41 endpoint and verify successful submission
7. Validate zeep can parse MTOM response from mock endpoint
8. Document any zeep library limitations or configuration requirements discovered
9. Provide code sample demonstrating MTOM attachment handling
10. Make go/no-go recommendation on zeep library with alternatives if needed

## Tasks / Subtasks

- [ ] Set up spike project structure (AC: 1, 2)
  - [ ] Create spike directory `src/ihe_test_util/ihe_transactions/` with `mtom.py`, `iti41.py`, `pix_add.py`, `soap_client.py`
  - [ ] Set up mock server in `src/ihe_test_util/mock_server/` with `app.py`, `iti41_endpoint.py`, `pix_add_endpoint.py`
  - [ ] Create sample CCD document (>10KB) in `mocks/data/documents/`
  - [ ] Initialize logging configuration

- [ ] Create minimal PIX Add SOAP message with zeep (AC: 1)
  - [ ] Research HL7v3 PRPA_IN201301UV02 message structure from IHE ITI-44 spec
  - [ ] Implement basic PIX Add message builder in `pix_add.py`
  - [ ] Add patient demographics (name, DOB, gender, patient ID with OID)
  - [ ] Verify correct HL7v3 namespaces and structure
  - [ ] Test message construction and serialization

- [ ] Build ITI-41 SOAP envelope with MTOM attachment (AC: 2, 3, 4, 5)
  - [ ] Research ITI-41 ProvideAndRegisterDocumentSetRequest structure from IHE spec
  - [ ] Implement MTOM attachment handling in `mtom.py`
  - [ ] Create ITI-41 transaction builder in `iti41.py` using zeep
  - [ ] Attach sample CCD (>10KB) with proper Content-ID reference
  - [ ] Include required metadata (patient ID, document unique ID, submission set ID, classCode, typeCode, formatCode)
  - [ ] Verify SOAP envelope structure matches IHE ITI-41 specification
  - [ ] Validate Content-ID references between metadata and attachment

- [ ] Create mock ITI-41 endpoint (AC: 6, 7)
  - [ ] Implement Flask mock endpoint at `/DocumentRepository_Service` in `iti41_endpoint.py`
  - [ ] Configure endpoint to accept MTOM multipart requests
  - [ ] Return XDSb RegistryResponse with success status
  - [ ] Save received documents to `mocks/logs/iti41-submissions/`
  - [ ] Log complete request/response for debugging

- [ ] Test against mock endpoint (AC: 6, 7)
  - [ ] Start mock server on `http://localhost:8080`
  - [ ] Submit ITI-41 transaction with zeep client
  - [ ] Verify successful submission (Status: Success)
  - [ ] Parse RegistryResponse and extract status
  - [ ] Validate zeep can handle MTOM response parsing
  - [ ] Verify document saved correctly on mock server

- [ ] Write integration tests (AC: 6, 7)
  - [ ] Create `tests/integration/test_pix_add_flow.py`
  - [ ] Create `tests/integration/test_iti41_flow.py`
  - [ ] Test PIX Add message construction and mock submission
  - [ ] Test ITI-41 MTOM workflow against mock endpoint
  - [ ] Verify response parsing
  - [ ] Ensure tests follow AAA pattern with proper mocking

- [ ] Document findings and provide recommendation (AC: 8, 9, 10)
  - [ ] Document zeep library capabilities and limitations
  - [ ] Note any configuration requirements (MTOM settings, plugins, etc.)
  - [ ] Create code sample in `examples/soap_mtom_example.py`
  - [ ] Document alternative libraries if zeep has significant limitations
  - [ ] Make clear go/no-go recommendation with justification
  - [ ] Add findings to spike report document

## Dev Notes

### Tech Stack Context
[Source: architecture/tech-stack.md]

**Primary Libraries for this Spike:**
- **zeep 4.2+**: SOAP/WSDL client with WS-Security support - the library being validated
- **lxml 5.1+**: XML processing for message construction and parsing
- **Flask 3.0+**: Mock server framework for test endpoints
- **requests 2.31+**: HTTP/HTTPS transport (used by zeep)
- **Python 3.10+**: Minimum version, use modern features like type hints

**Testing Tools:**
- **pytest 7.4+**: Testing framework
- **pytest-mock 3.12+**: Simplified mocking

### Project Structure Context
[Source: architecture/source-tree.md]

**File Locations for Implementation:**
- **IHE Transactions Module**: `src/ihe_test_util/ihe_transactions/`
  - `mtom.py` - MTOM attachment handling
  - `iti41.py` - ITI-41 transaction builder and submitter
  - `pix_add.py` - PIX Add message builder
  - `soap_client.py` - Zeep SOAP client wrapper

- **Mock Server Module**: `src/ihe_test_util/mock_server/`
  - `app.py` - Flask application
  - `iti41_endpoint.py` - Mock ITI-41 endpoint
  - `pix_add_endpoint.py` - Mock PIX Add endpoint

- **Mock Data**:
  - `mocks/data/documents/` - Sample CCD documents
  - `mocks/logs/iti41-submissions/` - Submission logs

- **Tests**:
  - `tests/unit/test_ihe_transactions.py` - Unit tests
  - `tests/integration/test_pix_add_flow.py` - PIX Add integration tests
  - `tests/integration/test_iti41_flow.py` - ITI-41 integration tests
  - `tests/fixtures/` - Test data (certificates, sample documents)

### IHE Specifications Context
[Source: architecture/external-apis.md]

**PIX Add (ITI-44/ITI-8):**
- **Documentation**: https://profiles.ihe.net/ITI/TF/Volume2/ITI-44.html
- **Message Format**: HL7 Version 3 XML (PRPA_IN201301UV02)
- **Required Elements**: Patient ID with OID, demographics (name, DOB, gender)
- **Response**: HL7v3 MCCI_IN000002UV01 acknowledgment with status (AA/AE/AR)
- **Mock Endpoint**: `http://localhost:8080/pix/add`

**ITI-41 (Provide and Register Document Set-b):**
- **Documentation**: https://profiles.ihe.net/ITI/TF/Volume2/ITI-41.html
- **Message Format**: SOAP with MTOM (MIME multipart) for document attachment
- **Required Metadata**: Patient ID, document unique ID, submission set ID, classCode, typeCode, formatCode
- **Document Format**: HL7 CCD (CCDA R2.1) as XML attachment
- **MTOM Details**: CCD attached with Content-ID reference in metadata
- **Response**: XDSb RegistryResponse with status (Success/Failure/PartialSuccess)
- **Mock Endpoint**: `http://localhost:8080/iti41/submit` or `http://localhost:8080/DocumentRepository_Service`
- **Timeout**: 60 seconds (documents can be large)

### Coding Standards
[Source: architecture/coding-standards.md]

**MANDATORY Requirements:**
- **Type Hints**: All function signatures must have complete type hints
- **Docstrings**: Google-style docstrings for all public functions
- **Logging**: NEVER use print() - always use logging module
- **IHE Transaction Logging**: MUST log complete request/response SOAP envelopes to audit files
- **Path Objects**: Use `pathlib.Path` not string paths for cross-platform compatibility
- **Exception Handling**: No bare except clauses - catch specific exceptions
- **Error Messages**: Must include actionable context (what failed and suggested fix)

**Code Style:**
- Formatter: black (88-character line length)
- Linter: ruff
- Type Checker: mypy strict mode

### Testing Standards
[Source: architecture/test-strategy-and-standards.md]

**Test Organization:**
- **Unit Tests**: `tests/unit/test_{module_name}.py`
  - Cover all public methods
  - Mock all external dependencies (file I/O, network)
  - Follow AAA pattern (Arrange, Act, Assert)
  - Coverage: 80%+ required

- **Integration Tests**: `tests/integration/`
  - Test component interactions
  - Use Flask test client for mock endpoints
  - Use pytest tmp_path fixtures for file operations
  - Test certificates in `tests/fixtures/`

**Example Test Pattern:**
```python
def test_parse_response(tmp_path):
    # Arrange
    response_xml = "<response>...</response>"
    
    # Act
    result = parse_iti41_response(response_xml)
    
    # Assert
    assert result.status == "Success"
```

**Coverage Goals:**
- Minimum: 75% (CI fails below)
- Target: 80%+
- Critical modules (IHE Transactions): 90%+

### Spike-Specific Notes

**Goal**: Validate zeep library can handle:
1. HL7v3 message construction for PIX Add
2. MTOM attachment packaging for ITI-41
3. Content-ID reference management
4. Response parsing (acknowledgments and registry responses)

**Success Criteria**: 
- zeep successfully constructs and submits both message types
- MTOM attachments work correctly with Content-ID references
- Response parsing works for both transaction types
- No major blockers or configuration complexity

**Deliverables**:
- Working code samples demonstrating both PIX Add and ITI-41
- Integration tests proving end-to-end functionality
- Documentation of zeep configuration requirements
- Clear go/no-go recommendation with justification

**If zeep has limitations, research alternatives**:
- suds-community
- python-zeep forks
- manual SOAP construction with lxml + requests

## Testing

[Source: architecture/test-strategy-and-standards.md]

**Test Framework**: pytest 7.4+

**Test File Locations**:
- Unit tests: `tests/unit/test_ihe_transactions.py`
- Integration tests: `tests/integration/test_pix_add_flow.py`, `tests/integration/test_iti41_flow.py`

**Testing Requirements**:
- Follow AAA pattern (Arrange, Act, Assert)
- Mock external dependencies (network calls, file I/O)
- Use pytest-mock for mocking
- Use Flask test client for mock endpoint testing
- Minimum 75% coverage, target 80%+
- This is a critical module, aim for 90%+ coverage

**Test Data**:
- Store test fixtures in `tests/fixtures/`
- Create sample CCD document (>10KB)
- Use pytest tmp_path for temporary file operations

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-03 | 1.0 | Initial story creation | Scrum Master (Bob) |

## Dev Agent Record

*This section will be populated by the development agent during implementation.*

### Agent Model Used

*To be filled by dev agent*

### Debug Log References

*To be filled by dev agent*

### Completion Notes List

*To be filled by dev agent*

### File List

*To be filled by dev agent*

## QA Results

*This section will be populated by the QA agent after story completion.*
