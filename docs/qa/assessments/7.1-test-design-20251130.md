# Test Design: Story 7.1 - Unit Test Suite Completion

**Date:** 2025-11-30
**Designer:** Quinn (Test Architect)

---

## Test Strategy Overview

| Metric | Value |
|--------|-------|
| **Total test scenarios** | 28 |
| **Unit tests** | 8 (29%) |
| **Integration tests** | 12 (43%) |
| **E2E tests** | 8 (29%) |
| **Priority distribution** | P0: 6, P1: 12, P2: 8, P3: 2 |

### Strategy Rationale

Story 7.1 is a **meta-testing story** - it's about completing the unit test suite itself. The verification approach differs from typical feature stories:

- **Unit tests** verify individual test utilities and fixtures work correctly
- **Integration tests** verify coverage measurement and reporting work across modules
- **E2E tests** verify the complete test suite execution and CI integration

---

## Test Scenarios by Acceptance Criteria

### AC1: Unit tests for all modules (csv_parser, template_engine, ihe_transactions, saml, transport, utils, cli)

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 7.1-INT-001 | Integration | P0 | `test_all_modules_have_unit_tests` - Verify each src/ module has corresponding test file | Module enumeration requires filesystem scan |
| 7.1-INT-002 | Integration | P1 | `test_csv_parser_module_tests_exist` - Verify parser.py, validator.py, id_generator.py have tests | Cross-file verification |
| 7.1-INT-003 | Integration | P1 | `test_ihe_transactions_module_tests_exist` - Verify critical module test coverage | Critical module validation |
| 7.1-INT-004 | Integration | P1 | `test_saml_module_tests_exist` - Verify security-critical tests | Security module validation |

### AC2: Test coverage measured using pytest-cov plugin

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 7.1-UNIT-001 | Unit | P0 | `test_pytest_cov_installed` - Verify pytest-cov is in dependencies | Pure dependency check |
| 7.1-INT-005 | Integration | P0 | `test_coverage_measurement_works` - Run pytest --cov and verify output generated | Multi-tool integration |
| 7.1-INT-006 | Integration | P1 | `test_coverage_per_module_reported` - Verify coverage breakdown by module | Report format validation |

### AC3: Target 80%+ coverage achieved (per NFR13)

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 7.1-E2E-001 | E2E | P0 | `test_overall_coverage_80_percent` - Run full suite, verify >= 80% | Complete suite execution |
| 7.1-E2E-002 | E2E | P0 | `test_critical_modules_90_percent` - Verify ihe_transactions, saml >= 90% | Critical path validation |
| 7.1-INT-007 | Integration | P1 | `test_coverage_by_module_breakdown` - Verify per-module coverage metrics | Module-level verification |

### AC4: Test fixtures for common test data (CSVs, templates, certificates, SOAP messages)

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 7.1-UNIT-002 | Unit | P1 | `test_csv_fixtures_available` - Verify sample CSV fixtures exist and load | Pure fixture validation |
| 7.1-UNIT-003 | Unit | P1 | `test_certificate_fixtures_available` - Verify PEM/DER fixtures exist | Pure fixture validation |
| 7.1-UNIT-004 | Unit | P1 | `test_template_fixtures_available` - Verify CCD template fixtures | Pure fixture validation |
| 7.1-UNIT-005 | Unit | P2 | `test_soap_message_fixtures_available` - Verify SOAP samples exist | Supporting fixture check |
| 7.1-INT-008 | Integration | P2 | `test_fixtures_reusable_across_tests` - Verify fixtures are shared correctly | Fixture sharing behavior |

### AC5: Mocking used for external dependencies (file I/O, network calls)

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 7.1-UNIT-006 | Unit | P1 | `test_pytest_mock_available` - Verify pytest-mock is importable | Pure dependency check |
| 7.1-INT-009 | Integration | P1 | `test_network_mocked_in_tests` - Verify no actual network calls in unit tests | Mock behavior verification |
| 7.1-INT-010 | Integration | P2 | `test_file_io_uses_tmp_path` - Verify tests use pytest tmp_path | Isolation verification |

### AC6: Parametrized tests cover multiple scenarios efficiently

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 7.1-UNIT-007 | Unit | P2 | `test_parametrize_decorator_usage` - Grep for @pytest.mark.parametrize usage | Static code check |
| 7.1-INT-011 | Integration | P2 | `test_parametrized_tests_run_correctly` - Run parametrized test, verify all iterations | Runtime behavior |
| 7.1-E2E-003 | E2E | P3 | `test_parametrized_coverage_efficient` - Verify parametrized tests increase coverage efficiently | Efficiency metric |

### AC7: Test organization mirrors source code structure

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 7.1-UNIT-008 | Unit | P2 | `test_test_file_naming_convention` - Verify test_*.py naming | Pure naming check |
| 7.1-INT-012 | Integration | P1 | `test_test_structure_mirrors_source` - Verify tests/unit/ structure matches src/ | Cross-directory comparison |

### AC8: Fast execution: complete unit suite runs in < 2 minutes

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 7.1-E2E-004 | E2E | P0 | `test_unit_suite_execution_under_2_minutes` - Time complete unit test run | Complete suite execution |
| 7.1-E2E-005 | E2E | P2 | `test_no_slow_tests_over_500ms` - Verify no individual test > 0.5s | Performance profiling |

### AC9: Coverage report generated in HTML and terminal formats

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 7.1-E2E-006 | E2E | P1 | `test_html_coverage_report_generated` - Verify htmlcov/ directory created | File generation |
| 7.1-E2E-007 | E2E | P1 | `test_terminal_coverage_report_displayed` - Verify console output includes coverage | Output format |

### AC10: CI pipeline fails if coverage drops below 75%

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 7.1-E2E-008 | E2E | P1 | `test_ci_coverage_threshold_configured` - Verify pyproject.toml/coveragerc has 75% minimum | Configuration validation |
| 7.1-INT-013 | Integration | P3 | `test_coverage_failure_exit_code` - Run with low coverage, verify non-zero exit | Exit code behavior |

---

## Test Scenarios Summary

### Unit Tests (8 tests)
```
7.1-UNIT-001: test_pytest_cov_installed (P0)
7.1-UNIT-002: test_csv_fixtures_available (P1)
7.1-UNIT-003: test_certificate_fixtures_available (P1)
7.1-UNIT-004: test_template_fixtures_available (P1)
7.1-UNIT-005: test_soap_message_fixtures_available (P2)
7.1-UNIT-006: test_pytest_mock_available (P1)
7.1-UNIT-007: test_parametrize_decorator_usage (P2)
7.1-UNIT-008: test_test_file_naming_convention (P2)
```

### Integration Tests (12 tests)
```
7.1-INT-001: test_all_modules_have_unit_tests (P0)
7.1-INT-002: test_csv_parser_module_tests_exist (P1)
7.1-INT-003: test_ihe_transactions_module_tests_exist (P1)
7.1-INT-004: test_saml_module_tests_exist (P1)
7.1-INT-005: test_coverage_measurement_works (P0)
7.1-INT-006: test_coverage_per_module_reported (P1)
7.1-INT-007: test_coverage_by_module_breakdown (P1)
7.1-INT-008: test_fixtures_reusable_across_tests (P2)
7.1-INT-009: test_network_mocked_in_tests (P1)
7.1-INT-010: test_file_io_uses_tmp_path (P2)
7.1-INT-011: test_parametrized_tests_run_correctly (P2)
7.1-INT-012: test_test_structure_mirrors_source (P1)
```

### E2E Tests (8 tests)
```
7.1-E2E-001: test_overall_coverage_80_percent (P0)
7.1-E2E-002: test_critical_modules_90_percent (P0)
7.1-E2E-003: test_parametrized_coverage_efficient (P3)
7.1-E2E-004: test_unit_suite_execution_under_2_minutes (P0)
7.1-E2E-005: test_no_slow_tests_over_500ms (P2)
7.1-E2E-006: test_html_coverage_report_generated (P1)
7.1-E2E-007: test_terminal_coverage_report_displayed (P1)
7.1-E2E-008: test_ci_coverage_threshold_configured (P1)
```

---

## Recommended Execution Order

### Phase 1: P0 Critical (6 tests) - Fail Fast
```bash
# P0 Unit tests
python -m pytest tests/unit/test_7_1_verification.py::test_pytest_cov_installed -v

# P0 Integration tests
python -m pytest tests/integration/test_7_1_coverage.py::test_all_modules_have_unit_tests -v
python -m pytest tests/integration/test_7_1_coverage.py::test_coverage_measurement_works -v

# P0 E2E tests
python -m pytest tests/e2e/test_7_1_suite.py::test_overall_coverage_80_percent -v
python -m pytest tests/e2e/test_7_1_suite.py::test_critical_modules_90_percent -v
python -m pytest tests/e2e/test_7_1_suite.py::test_unit_suite_execution_under_2_minutes -v
```

### Phase 2: P1 Core (12 tests)
All P1 tests in order of execution

### Phase 3: P2+ Secondary (10 tests)
P2 and P3 tests as time permits

---

## Risk Coverage

| Risk | Test IDs | Mitigation |
|------|----------|------------|
| Coverage regression | 7.1-E2E-001, 7.1-E2E-002 | Automated coverage verification |
| Slow test accumulation | 7.1-E2E-004, 7.1-E2E-005 | Performance monitoring |
| Missing module tests | 7.1-INT-001 thru 7.1-INT-004 | Module enumeration check |
| Fixture not reusable | 7.1-INT-008 | Fixture sharing verification |
| CI not enforcing threshold | 7.1-E2E-008, 7.1-INT-013 | Configuration and behavior check |

---

## Quality Checklist

- [x] Every AC has test coverage (10/10 ACs covered)
- [x] Test levels are appropriate (no over-testing)
- [x] No duplicate coverage across levels
- [x] Priorities align with business risk
- [x] Test IDs follow naming convention (7.1-{LEVEL}-{SEQ})
- [x] Scenarios are atomic and independent

---

## Gate YAML Block

```yaml
test_design:
  scenarios_total: 28
  by_level:
    unit: 8
    integration: 12
    e2e: 8
  by_priority:
    p0: 6
    p1: 12
    p2: 8
    p3: 2
  coverage_gaps: []
  ac_coverage: 10/10
```

---

## Trace References

```text
Test design matrix: docs/qa/assessments/7.1-test-design-20251130.md
P0 tests identified: 6
Critical modules verified: ihe_transactions, saml
